{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9a672e07",
   "metadata": {},
   "source": [
    "# Customer Segmentation and Classification\n",
    "Problem:\n",
    "User clickstream data and information about a group of hotels is provided.\n",
    "\n",
    "Objective:\n",
    "Segment users into 3 clusters and predict to which cluster a new customer belongs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0ea0f562",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "# Tell iPython to include plots inline in the notebook\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2e386b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read dataset\n",
    "globalData = pd.read_csv(\"globalTrain.csv\")\n",
    "\n",
    "#print globalData.head() # print the first 5 rows\n",
    "globalData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fb5ea37",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking variables data types\n",
    "globalData.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20235ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Renaming columns and changing data types\n",
    "\n",
    "globalData=globalData.rename(columns = {' HotelCode':'HotelCode'})\n",
    "globalData=globalData.rename(columns = {' Age':'Age'})\n",
    "globalData=globalData.rename(columns = {' Gender':'Gender'})\n",
    "globalData=globalData.rename(columns = {' Number of Rooms':'Number of Rooms'})\n",
    "globalData=globalData.rename(columns = {' Check in date':'Check in date'})\n",
    "globalData=globalData.rename(columns = {' Check Out Date':'Check Out Date'})\n",
    "globalData=globalData.rename(columns = {' Seen Price':'Seen Price'})\n",
    "globalData=globalData.rename(columns = {' isClicked':'isClicked'})\n",
    "globalData=globalData.rename(columns = {' isBooked':'isBooked'})\n",
    "globalData=globalData.rename(columns = {' Segment':'Segment'})\n",
    "\n",
    "globalData['Booking Date'] =  pd.to_datetime(globalData['Booking Date'])\n",
    "globalData['Check in date'] =  pd.to_datetime(globalData['Check in date'])\n",
    "globalData['Check Out Date'] =  pd.to_datetime(globalData['Check Out Date'])\n",
    "globalData['isClicked'] =  globalData['isClicked'].astype(str)\n",
    "globalData['isBooked'] =  globalData['isBooked'].astype(str)\n",
    "\n",
    "globalData['Stay Period'] = (globalData['Check Out Date'] - globalData['Check in date'])/np.timedelta64(1, 'D');\n",
    "globalData['Travel Gap'] = (globalData['Check in date'] - globalData['Booking Date'])/np.timedelta64(1, 'D');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df58ea57",
   "metadata": {},
   "outputs": [],
   "source": [
    "globalData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8462f138",
   "metadata": {},
   "outputs": [],
   "source": [
    "globalData.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3ce0519",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now separate training data\n",
    "X_train=globalData.iloc[:,[3,4,5,8,9,10,16,17,18,19]];\n",
    "#X_train=globalData.iloc[:,[3]];\n",
    "X_train['Gender'] = X_train['Gender'].replace(['male', 'female'], [1, 0])\n",
    "X_train['isClicked'] = X_train['isClicked'].replace(['True', 'False'], [1, 0])\n",
    "X_train['isBooked'] = X_train['isBooked'].replace(['True', 'False'], [1, 0])\n",
    "X_train[X_train < 0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7febdf94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import clustering modules\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29d82bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=10)\n",
    "pca.fit(X_train)\n",
    "# Print the components and the amount of variance in the data contained in each dimension\n",
    "#print pca.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6eaddf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: First we reduce the data to two dimensions using PCA to capture variation\n",
    "pca = PCA(n_components=3)\n",
    "reduced_data = pca.fit_transform(X_train)\n",
    "print(reduced_data[:10]) #print upto 10 elements\n",
    "print(pca.components_)\n",
    "print(pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d431d7c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set()  # for plot styling\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "585fb790",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train the clustering algorythm\n",
    "kmeans = KMeans(init='k-means++', n_clusters=3, n_init=10)\n",
    "kmeans.fit(reduced_data)\n",
    "y_kmeans = kmeans.predict(reduced_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1018f4c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(reduced_data[:, 0], reduced_data[:, 2], c=y_kmeans, s=50, cmap='viridis')\n",
    "centers = kmeans.cluster_centers_\n",
    "plt.scatter(centers[:, 0], centers[:, 2], c='black', s=200, alpha=0.5);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2885d109",
   "metadata": {},
   "outputs": [],
   "source": [
    "globalData['cluster'] = y_kmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8776e685",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparing Clusters\n",
    "import seaborn as sns\n",
    " \n",
    "sns.boxplot(x=globalData[\"cluster\"], y=globalData[\"Seen Price\"] )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac91d7f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "globalData.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb658364",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preprocessing for scaling\n",
    "X =globalData.iloc[:,[3,4,5,8,9,10,16,17,18,19]];\n",
    "\n",
    "X['Gender'] = X['Gender'].replace(['male', 'female'], [1, 0])\n",
    "X['isClicked'] = X['isClicked'].replace(['True', 'False'], [1, 0])\n",
    "X['isBooked'] = X['isBooked'].replace(['True', 'False'], [1, 0])\n",
    "\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a14108e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scaling values to 0-100\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "print(scaler.fit(X))\n",
    "\n",
    "scaled_X = scaler.transform(X)\n",
    "X1 = pd.DataFrame(scaled_X)\n",
    "X1.columns = X.columns\n",
    "\n",
    "X1.head()\n",
    "X2 = X1*100\n",
    "X2['cluster'] = y_kmeans\n",
    "X2.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cabaad79",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Groupng data into clusters\n",
    "\n",
    "grouped = X2.groupby('cluster').agg({'Age': ['median'], 'Seen Price': ['median'], 'Star Rating': ['median'], 'TripAdvisor Rating': ['median'], 'Stay Peri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04a8e01b",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped.reset_index()\n",
    "grouped.columns = ['Age', 'Seen Price', 'Star Rating', 'TripAdvisor Rating', 'Stay Period']\n",
    "grouped.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15c12971",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating radar charts for clusters\n",
    "\n",
    "\n",
    "# Libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from math import pi\n",
    "\n",
    "# Set data\n",
    "df = pd.DataFrame({\n",
    "'group': ['0','1','2'],\n",
    "'Age': grouped['Age'].tolist(),\n",
    "'Seen Price': grouped['Seen Price'].tolist(),\n",
    "'Star Rating': grouped['Star Rating'].tolist(),\n",
    "'TripAdvisor Rating': grouped['TripAdvisor Rating'].tolist(),\n",
    "'Stay Period': grouped['Stay Period'].tolist(),\n",
    "})\n",
    "\n",
    "# ------- PART 1: Define a function that do a plot for one line of the dataset!\n",
    "\n",
    "def make_spider( row, title, color):\n",
    "\n",
    "# number of variable\n",
    "    categories=list(df)[1:]\n",
    "    N = len(categories)\n",
    "\n",
    "# What will be the angle of each axis in the plot? (we divide the plot / number of variable)\n",
    "    angles = [n / float(N) * 2 * pi for n in range(N)]\n",
    "    angles += angles[:1]\n",
    "\n",
    "# Initialise the spider plot\n",
    "    ax = plt.subplot(2,2,row+1, polar=True, )\n",
    "\n",
    "# If you want the first axis to be on top:\n",
    "    ax.set_theta_offset(pi / 2)\n",
    "    ax.set_theta_direction(-1)\n",
    "\n",
    "# Draw one axe per variable + add labels labels yet\n",
    "    plt.xticks(angles[:-1], categories, color='grey', size=8)\n",
    "\n",
    "# Draw ylabels\n",
    "    ax.set_rlabel_position(0)\n",
    "    plt.yticks([25,50,75], [\"25\",\"50\",\"75\"], color=\"grey\", size=7)\n",
    "    plt.ylim(0,100)\n",
    "\n",
    "# Ind1\n",
    "    values=df.loc[row].drop('group').values.flatten().tolist()\n",
    "    values += values[:1]\n",
    "    ax.plot(angles, values, color=color, linewidth=2, linestyle='solid')\n",
    "    ax.fill(angles, values, color=color, alpha=0.4)\n",
    "\n",
    "# Add a title\n",
    "    plt.title(title, size=11, color=color, y=1.1)\n",
    "\n",
    "# ------- PART 2: Apply to all individuals\n",
    "# initialize the figure\n",
    "my_dpi=96\n",
    "plt.figure(figsize=(1000/my_dpi, 1000/my_dpi), dpi=my_dpi)\n",
    "\n",
    "# Create a color palette:\n",
    "my_palette = plt.cm.get_cmap(\"Set2\", len(df.index))\n",
    "\n",
    "# Loop to plot\n",
    "for row in range(0, len(df.index)):\n",
    "    make_spider( row=row, title='group '+df['group'][row], color=my_palette(row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b93d6a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(len(globalData))\n",
    "globalData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4689d2d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now separate training data - Target\n",
    "#X_train=globalData.drop(['Segment', 'cluster'], axis=1)\n",
    "y_train=globalData.iloc[:,[20]]\n",
    "\n",
    "print(X_train.head())\n",
    "print(y_train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d10f89f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# First, decide how many training vs test samples you want\n",
    "num_test = 40000\n",
    "X_train_cv, X_test_cv, y_train_cv, y_test_cv = train_test_split(X_train, y_train, test_size=num_test)\n",
    "print(\"Training set: {} samples\".format(X_train_cv.shape[0]))\n",
    "print(\"Test set: {} samples\".format(X_test_cv.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15dbfd39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "def train_classifier(clf, X_train, y_train):\n",
    "    print(\"Training {}...\".format(clf.__class__.__name__))\n",
    "    start = time.time()\n",
    "    clf.fit(X_train, y_train)\n",
    "    end = time.time()\n",
    "    print(\"Done!\\nTraining time (secs): {:.3f}\".format(end - start))\n",
    "    return (end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "248f4770",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit model to training data\n",
    "#Best classifier\n",
    "import time as time\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import svm, naive_bayes\n",
    "from sklearn import linear_model\n",
    "from  sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "\n",
    "#clf = DecisionTreeClassifier(random_state=0)\n",
    "#clf = DecisionTreeClassifier(min_samples_split= 2, max_leaf_nodes= 32, criterion= 'entropy',\n",
    "#                             max_depth = 9, min_samples_leaf=179)\n",
    "#clf = DecisionTreeClassifier(min_samples_split= 21, max_leaf_nodes= 20, criterion= 'gini',\n",
    "#                             max_depth = None, min_samples_leaf=11)\n",
    "\n",
    "#dtr_params = {'criterion':(\"gini\",\"entropy\")}\n",
    "#dtc2 = DecisionTreeClassifier(random_state=0)\n",
    "#clf = linear_model.LogisticRegression()\n",
    "#clf = grid_search.GridSearchCV(dtc2, dtr_params)\n",
    "\n",
    "#dtr_params = {'criterion':(\"gini\",\"entropy\"),'presort':(\"True\",\"False\"),\n",
    "#              'min_weight_fraction_leaf':(0,0.25,0.5), 'min_samples_leaf':(1,2,3),\n",
    "#              'min_samples_split':(2,4,8,16,32),'min_samples_split':(2,4,8,16), \n",
    "#              'max_features':(\"auto\",\"sqrt\",\"log2\"),'max_depth':np.arange(1,5,1)}\n",
    "#dtc2 = DecisionTreeClassifier(random_state=0)\n",
    "#clf = grid_search.GridSearchCV(dtc2, dtr_params)   \n",
    "\n",
    "#from  sklearn.ensemble import RandomForestClassifier\n",
    "#clf = RandomForestClassifier()\n",
    "#clf1 = RandomForestClassifier(n_estimators=20)\n",
    "# use a full grid over all parameters\n",
    "#param_grid = {#\"max_depth\": [3, None],\n",
    "              #\"max_features\": [1, 3, 10],\n",
    "              #\"min_samples_split\": [1, 3, 10],\n",
    "              #\"min_samples_leaf\": [1, 3, 10],\n",
    "              #\"bootstrap\": [True, False],\n",
    "              # \"criterion\": [\"gini\", \"entropy\"]\n",
    "              #  \"n_estimators\": [5, 20,30]}\n",
    "#clf = GridSearchCV(clf1, param_grid=param_grid)\n",
    "\n",
    "#parameters={'C' : [.005,.05,.5,1.,10.,100.,],\n",
    "#'fit_intercept' : [True, False],\n",
    "#'class_weight': [ None,'balanced'],\n",
    "#'random_state' : [None,42],\n",
    "#'penalty': ['l1', 'l2']\n",
    "#}\n",
    "#clf = svm.SVC()\n",
    "\n",
    "#SVC does not work\n",
    "#parameters = {'kernel':('linear', 'rbf'), 'C':[1, 20]}\n",
    "#svr = svm.SVC()\n",
    "#clf = SVC(kernel=\"linear\", C=1.0)\n",
    "\n",
    "#Bad results\n",
    "#clf= GaussianNB()\n",
    "\n",
    "#clf=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
    "#    decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
    "#    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
    "#    tol=0.001, verbose=False)\n",
    "\n",
    "#from sklearn.linear_model import LogisticRegression\n",
    "#clf = LogisticRegression()\n",
    "\n",
    "\n",
    "#from sklearn.linear_model import SGDRegressor\n",
    "#clf = SGDRegressor(alpha=0.0001, average=False, epsilon=0.1, eta0=0.01,\n",
    "#             fit_intercept=True, l1_ratio=0.15, learning_rate='invscaling',\n",
    "#             loss='squared_loss', n_iter=5, penalty='l2', power_t=0.25,\n",
    "#             random_state=None, shuffle=True, verbose=0, warm_start=False)\n",
    "\n",
    "#from sklearn.naive_bayes import BernoulliNB\n",
    "#clf = BernoulliNB()\n",
    "\n",
    "#from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "clf=PassiveAggressiveClassifier()\n",
    "\n",
    "#Works\n",
    "#from sklearn.neighbors import KNeighborsClassifier\n",
    "#clf = KNeighborsClassifier(n_neighbors=35)\n",
    "\n",
    "#Works\n",
    "#from  sklearn.ensemble import RandomForestClassifier\n",
    "#clf = RandomForestClassifier(criterion='entropy',n_estimators=100, max_features=None,random_state=None)\n",
    "#clf = RandomForestClassifier(n_estimators=20,min_samples_split=4)\n",
    "\n",
    "\n",
    "#Works\n",
    "#from  sklearn.ensemble import RandomForestClassifier\n",
    "#clf = RandomForestClassifier(n_estimators=100)\n",
    "#clf = RandomForestClassifier(n_estimators=100,max_features=None)\n",
    "\n",
    "#Works\n",
    "#from  sklearn.ensemble import AdaBoostClassifier\n",
    "#clf = AdaBoostClassifier(n_estimators=50)\n",
    "#clf = AdaBoostClassifier(n_estimators=60,learning_rate=0.65)\n",
    "\n",
    "#from sklearn.tree import DecisionTreeClassifier\n",
    "#clf2 = DecisionTreeClassifier(min_samples_split= 2, max_leaf_nodes= 20, criterion= 'gini',\n",
    "#                             max_depth = None, min_samples_leaf=1)\n",
    "#clf = AdaBoostClassifier(base_estimator=clf2,n_estimators=1,learning_rate=18,algorithm='SAMME')\n",
    "\n",
    "\n",
    "#clf1 = AdaBoostClassifier()\n",
    "#param_grid = { \"n_estimators\": [5, 20,30]}\n",
    "#lf = GridSearchCV(clf1, param_grid=param_grid)\n",
    "\n",
    "#from  sklearn.ensemble import RandomForestClassifier\n",
    "#clf1 = RandomForestClassifier(n_estimators=20)\n",
    "#clf = AdaBoostClassifier(base_estimator=clf1,n_estimators=50)\n",
    "\n",
    "#Works\n",
    "#from  sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "#clf = LinearDiscriminantAnalysis(solver='eigen', shrinkage='auto', tol=0.0001)\n",
    "\n",
    "#Works\n",
    "#from  sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "#clf = QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0, store_covariances=False, tol=0.000000001)\n",
    "\n",
    "train_classifier(clf, X_train_cv, y_train_cv) # note: using entire training set here\n",
    "#print clf # you can inspect the learned model by printing it\n",
    "\n",
    "print(\"Successfull!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "741cd4ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predict on training set and compute F1 score\n",
    "from sklearn.metrics import f1_score\n",
    "def predict_labels(clf, features, target):\n",
    "    #print \"Predicting labels using {}...\".format(clf.__class__.__name__)\n",
    "    start = time.time()\n",
    "    y_pred = clf.predict(features)\n",
    "    end = time.time()\n",
    "    #print \"Done!\\nPrediction time (secs): {:.3f}\".format(end - start)\n",
    "    #return f1_score(target.values, y_pred, pos_label='yes')\n",
    "    return f1_score(target.values, y_pred, average='micro') , (end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e91bf40f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print y_train.head()\n",
    "#print X_train.head()\n",
    "train_cv_f1_score = predict_labels(clf, X_train_cv, y_train_cv)\n",
    "#print \"F1 score for training set: {}\".format(train_cv_f1_score)\n",
    "# Predict on test data\n",
    "test_cv_f1_score = predict_labels(clf, X_test_cv, y_test_cv)\n",
    "#print \"F1 score for test set: {}\".format(test_cv_f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79516bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Report\n",
    "from astropy.table import Table, Column\n",
    "import time as time\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import svm, naive_bayes\n",
    "#from sklearn.grid_search import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn import linear_model\n",
    "from  sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from  sklearn.ensemble import AdaBoostClassifier\n",
    "from  sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c9e986",
   "metadata": {},
   "outputs": [],
   "source": [
    "noOfTypes =10;\n",
    "t1 = Table(names=('Type','Training time' ,'Prediction time-Training', 'F1 score-Training', \n",
    "                  'Prediction time-Testing', 'F1 score-Testing'), dtype=('S25', 'f4','f4', 'f4','f4', 'f4'))\n",
    "\n",
    "for i in range(0,noOfTypes):\n",
    "    if i==0:\n",
    "        clf=PassiveAggressiveClassifier();\n",
    "    if i==1:\n",
    "        clf=GaussianNB(); \n",
    "    if i==2:    \n",
    "        clf = DecisionTreeClassifier(random_state=0)\n",
    "    if i==3:    \n",
    "        clf = RandomForestClassifier()\n",
    "    if i==4:    \n",
    "        clf = BernoulliNB()\n",
    "    if i==5:    \n",
    "        clf = LogisticRegression()\n",
    "    if i==6:    \n",
    "        clf = KNeighborsClassifier()\n",
    "    if i==7:    \n",
    "        clf = AdaBoostClassifier()\n",
    "    if i==8:    \n",
    "        clf = LinearDiscriminantAnalysis()\n",
    "    if i==9:    \n",
    "        clf = QuadraticDiscriminantAnalysis()\n",
    "        \n",
    "    clfType=clf.__class__.__name__;\n",
    "    trainTime=train_classifier(clf, X_train_cv, y_train_cv);\n",
    "    retVec=predict_labels(clf, X_train_cv, y_train_cv)\n",
    "    trainF1Score=retVec[0];\n",
    "    trainTime=retVec[1];\n",
    "    retVec1=predict_labels(clf, X_test_cv, y_test_cv)\n",
    "    testF1Score=retVec1[0];\n",
    "    testTime=retVec1[1];\n",
    "    t1.add_row((clfType,trainTime,trainTime, trainF1Score,testTime, testF1Score))\n",
    "\n",
    "#t1 = Table(names=('Type','Training time' ,'Prediction time-Training', 'F1 score-Training', 'Prediction time-Testing', 'F1 score-Testing'), dtype=('S13', 'f4','f4', 'f4','f4', 'f4'))\n",
    "#t1.add_row(('SVC',1,100, 3,4, 5))\n",
    "#t1.add_row(('SVC',2, 200, 33,44, 55))\n",
    "\n",
    "t1    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d13d280f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
